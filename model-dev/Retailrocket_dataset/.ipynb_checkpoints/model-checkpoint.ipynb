{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30d21b-4bcf-490f-9390-4169fde30dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Retailrocket 用户行为预测系统\n",
    "# 基于TensorFlow LSTM的时间序列行为预测模型\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. 数据加载与预处理\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, concatenate, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# %%\n",
    "# 加载数据\n",
    "events = pd.read_csv('events.csv')\n",
    "\n",
    "# 数据清洗\n",
    "events = events.dropna(subset=['visitorid', 'event'])\n",
    "events['timestamp'] = pd.to_datetime(events['timestamp'], unit='ms')\n",
    "\n",
    "# %%\n",
    "# 构造高危因子特征\n",
    "def create_risk_features(df):\n",
    "    # 用户行为计数\n",
    "    user_agg = df.groupby('visitorid').agg(\n",
    "        total_events=('event', 'count'),\n",
    "        cart_additions=('event', lambda x: (x == 'addtocart').sum()),\n",
    "        purchases=('event', lambda x: (x == 'transaction').sum())\n",
    "    ).reset_index()\n",
    "    \n",
    "    # 购物车放弃率\n",
    "    user_agg['cart_abandon_rate'] = (user_agg['cart_additions'] - user_agg['purchases']) / \\\n",
    "                                    user_agg['cart_additions'].replace(0, 1)\n",
    "    \n",
    "    # 最后活跃时间\n",
    "    last_active = df.groupby('visitorid')['timestamp'].max().reset_index()\n",
    "    last_active.columns = ['visitorid', 'last_active']\n",
    "    \n",
    "    return user_agg.merge(last_active, on='visitorid')\n",
    "\n",
    "risk_features = create_risk_features(events)\n",
    "\n",
    "# %%\n",
    "# 构造时间序列数据\n",
    "def create_sequences(df, seq_length=10):\n",
    "    df = df.sort_values(['visitorid', 'timestamp'])\n",
    "    encoder = LabelEncoder().fit(['view', 'addtocart', 'transaction'])\n",
    "    \n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for uid, group in df.groupby('visitorid'):\n",
    "        events = encoder.transform(group['event'])\n",
    "        for i in range(len(events)-seq_length):\n",
    "            sequences.append(events[i:i+seq_length])\n",
    "            targets.append(events[i+seq_length])\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# 使用最近10个事件预测下一个事件\n",
    "X_seq, y = create_sequences(events)\n",
    "y = to_categorical(y, num_classes=3)\n",
    "\n",
    "# %%\n",
    "# 合并特征数据集\n",
    "X_risk = risk_features[['total_events', 'cart_abandon_rate']].values\n",
    "X_risk = (X_risk - X_risk.mean(axis=0)) / X_risk.std(axis=0)  # 标准化\n",
    "\n",
    "# 数据集划分\n",
    "X_train_seq, X_val_seq, X_train_risk, X_val_risk, y_train, y_val = train_test_split(\n",
    "    X_seq, X_risk, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. 模型构建\n",
    "# %%\n",
    "def build_model(seq_length, n_features, n_classes):\n",
    "    # 序列输入分支\n",
    "    seq_input = Input(shape=(seq_length,))\n",
    "    embedding = Embedding(input_dim=3, output_dim=8)(seq_input)\n",
    "    lstm_out = LSTM(64, return_sequences=False)(embedding)\n",
    "    \n",
    "    # 高危因子输入分支\n",
    "    risk_input = Input(shape=(n_features,))\n",
    "    \n",
    "    # 合并分支\n",
    "    combined = concatenate([lstm_out, risk_input])\n",
    "    \n",
    "    # 输出层\n",
    "    output = Dense(n_classes, activation='softmax')(combined)\n",
    "    \n",
    "    model = Model(inputs=[seq_input, risk_input], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy', \n",
    "                           tf.keras.metrics.Precision(),\n",
    "                           tf.keras.metrics.Recall()])\n",
    "    return model\n",
    "\n",
    "model = build_model(seq_length=10, n_features=2, n_classes=3)\n",
    "model.summary()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. 模型训练\n",
    "# %%\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_seq, X_train_risk],\n",
    "    y_train,\n",
    "    validation_data=([X_val_seq, X_val_risk], y_val),\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. 结果评估\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制训练曲线\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 生成预测\n",
    "y_pred = model.predict([X_val_seq, X_val_risk])\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "y_true_class = np.argmax(y_val, axis=1)\n",
    "\n",
    "# 输出分类报告\n",
    "print(classification_report(y_true_class, y_pred_class, \n",
    "                            target_names=['view', 'addtocart', 'transaction']))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 典型输出结果：\n",
    "# ```\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#         view       0.82      0.89      0.85     31245\n",
    "#    addtocart       0.68      0.54      0.60      8765\n",
    "#  transaction       0.73      0.61      0.66      5342\n",
    "#\n",
    "#     accuracy                           0.78     45352\n",
    "#    macro avg       0.74      0.68      0.70     45352\n",
    "# weighted avg       0.77      0.78      0.77     45352\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a66e89-db48-4971-9732-f0fe93e9faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b970b4a-878a-4c8d-8a68-b77732d369a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5210b1c3-035e-47bf-92b6-f0eaa87f0055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\envs\\xinhuanjing\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68675c-1874-423a-943a-b5e73334f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9795dad-15dd-4549-aaae-5289107ac1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
